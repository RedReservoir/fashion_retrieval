{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import src.utils.tensor\n",
    "\n",
    "torch.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in_feats = [\n",
    "    torch.rand((96, 56, 56)),\n",
    "    torch.rand((192, 28, 28)),\n",
    "    torch.rand((384, 14, 14)),\n",
    "    torch.rand((768, 7, 7))\n",
    "]\n",
    "\n",
    "feat_shapes = [tuple(in_feat.shape) for in_feat in in_feats]\n",
    "in_feat_idxs = [0, 2, 3]\n",
    "emb_sizes = [500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feats = [\n",
    "    torch.rand((1, 96, 112, 112)),\n",
    "    torch.rand((1, 192, 56, 56)),\n",
    "    torch.rand((1, 384, 28, 28)),\n",
    "    torch.rand((1, 768, 14, 14)),\n",
    "    torch.rand((1, 1536, 7, 7))\n",
    "]\n",
    "\n",
    "feat_shapes = [tuple(in_feat.shape[1:]) for in_feat in in_feats]\n",
    "in_feat_idxs = [1, 3, 4]\n",
    "emb_sizes = [500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feat_shapes = [feat_shapes[idx] for idx in in_feat_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(192, 56, 56), (768, 14, 14), (1536, 7, 7)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_feat_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zidx for zidx in reversed(range(len(in_feat_idxs) - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_conv_layers_list = [\n",
    "    round(math.log2(feat_shapes[in_feat_idxs[zidx]][1] / feat_shapes[in_feat_idxs[zidx+1]][1]))\n",
    "    for zidx in range(len(in_feat_idxs) - 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_conv_layers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels_list = [in_feat_shapes[0][0]] + emb_sizes[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[192, 500]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_channels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_feat_h_list = [feat_shape[1] for feat_shape in in_feat_shapes[1:]]\n",
    "down_feat_w_list = [feat_shape[2] for feat_shape in in_feat_shapes[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 7]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_feat_h_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 7]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_feat_w_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_1_channels_list = [in_feat_shapes[0][0]] + emb_sizes[:-1]\n",
    "cat_2_channels_list = [feat_shape[0] for feat_shape in in_feat_shapes[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[192, 500]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_1_channels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[768, 1536]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_2_channels_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_conv_layers_list = [\n",
    "    round(math.log2(feat_shapes[in_feat_idxs[zidx]][1] / feat_shapes[in_feat_idxs[zidx+1]][1]))\n",
    "    for zidx in reversed(range(len(in_feat_idxs) - 1))\n",
    "]\n",
    "\n",
    "num_channels_list = [in_feat_shapes[-1][0]] + emb_sizes[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_conv_layers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[768, 500]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_channels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_conv_layers = [\n",
    "    round(math.log2(max_feat_s / feat_shapes[idx][1]))\n",
    "    for idx in in_feat_idxs[:0:-1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_feat_idxs[-2::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Idxs of the features to pick for concatenating\n",
    "in_feat_idxs[-2::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Idxs of the features to pick for upsampling\n",
    "in_feat_idxs[:0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscale_ratios_h = [\n",
    "    round(math.log2(max_feat_h / feat_shapes[idx][1]))\n",
    "    for idx in in_feat_idxs\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscale_ratios_h = [\n",
    "    round(math.log2(max_feat_h / feat_shapes[idx][1]))\n",
    "    for idx in in_feat_idxs\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upscale_ratios_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 3.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.log2(upscale_ratios_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        in_feat_shapes = [feat_shapes[idx] for idx in in_feat_idxs]\n",
    "\n",
    "        # Upsampling\n",
    "\n",
    "        max_feat_h = max(feat_shape[1] for feat_shape in in_feat_shapes)\n",
    "        max_feat_w = max(feat_shape[2] for feat_shape in in_feat_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: feat\n",
      "shape:  torch.Size([768, 7, 7])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  147.07 KiB\n",
      "\n",
      "name: feat_up\n",
      "shape:  torch.Size([768, 56, 56])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  9.19 MiB\n"
     ]
    }
   ],
   "source": [
    "feat = feat_l4\n",
    "\n",
    "#\n",
    "\n",
    "conv_transpose_layer = torch.nn.ConvTranspose2d(\n",
    "    in_channels=feat.shape[0],\n",
    "    out_channels=feat.shape[0],\n",
    "    kernel_size=3,\n",
    "    padding=1,\n",
    "    stride=2,\n",
    "    output_padding=1\n",
    ")\n",
    "\n",
    "feat_up = conv_transpose_layer(conv_transpose_layer(conv_transpose_layer(feat)))\n",
    "\n",
    "src.utils.tensor.print_tensor_info(feat, \"feat\", nl=True)\n",
    "src.utils.tensor.print_tensor_info(feat_up, \"feat_up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: feat\n",
      "shape:  torch.Size([768, 7, 7])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  147.07 KiB\n",
      "\n",
      "name: feat_up\n",
      "shape:  torch.Size([768, 28, 28])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  2.30 MiB\n"
     ]
    }
   ],
   "source": [
    "feat = feat_l4\n",
    "\n",
    "#\n",
    "\n",
    "conv_transpose_layer = torch.nn.ConvTranspose2d(\n",
    "    in_channels=feat.shape[0],\n",
    "    out_channels=feat.shape[0],\n",
    "    kernel_size=3,\n",
    "    padding=1,\n",
    "    stride=4,\n",
    "    output_padding=3\n",
    ")\n",
    "\n",
    "feat_up = conv_transpose_layer(feat)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(feat, \"feat\", nl=True)\n",
    "src.utils.tensor.print_tensor_info(feat_up, \"feat_up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: feat\n",
      "shape:  torch.Size([768, 7, 7])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  147.07 KiB\n",
      "\n",
      "name: feat_up\n",
      "shape:  torch.Size([768, 13, 13])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  507.07 KiB\n"
     ]
    }
   ],
   "source": [
    "feat = feat_l4\n",
    "\n",
    "#\n",
    "\n",
    "conv_transpose_layer = torch.nn.ConvTranspose2d(\n",
    "    in_channels=feat.shape[0],\n",
    "    out_channels=feat.shape[0],\n",
    "    kernel_size=3,\n",
    "    padding=1,\n",
    "    stride=2,\n",
    "    dilation=1,\n",
    "    output_padding=0\n",
    ")\n",
    "\n",
    "feat_up = conv_transpose_layer(feat)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(feat, \"feat\", nl=True)\n",
    "src.utils.tensor.print_tensor_info(feat_up, \"feat_up\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "649142fb4cdab8a2d2387ea4a1c8e262f08b2b20e4af0e114d36ea602bf8b868"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
