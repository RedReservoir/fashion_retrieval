{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "import src.datasets.deep_fashion_ctsrbm\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import src.comps.backbones_cnn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.convnext_tiny()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(\"misc/convnext_tiny_model_arch.txt\", \"w\") as out_file:\n",
    "    print(model, file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctsrbm_image_transform = torchvision.models.ConvNeXt_Tiny_Weights.DEFAULT.transforms()\n",
    "ctsrbm_image_transform.antialias = True\n",
    "ctsrbm_dataset_dir = os.path.join(pathlib.Path.home(), \"data\", \"DeepFashion\", \"Consumer-to-shop Clothes Retrieval Benchmark\")\n",
    "ctsrbm_dataset = src.datasets.deep_fashion_ctsrbm.ConsToShopClothRetrBmkImageLoader(ctsrbm_dataset_dir, ctsrbm_image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7ff59f3f04c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "for idx in range(8):\n",
    "    model.features[idx].register_forward_hook(get_activation('features[{:d}]'.format(idx)))\n",
    "model.features.register_forward_hook(get_activation('features'))\n",
    "model.avgpool.register_forward_hook(get_activation('avgpool'))\n",
    "model.classifier.register_forward_hook(get_activation('classifier'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = ctsrbm_dataset[0][0][None, :]\n",
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input                torch.Size([1, 3, 224, 224])\n",
      "output               torch.Size([1, 1000])\n",
      "---\n",
      "features[0]          torch.Size([1, 96, 56, 56])\n",
      "features[1]          torch.Size([1, 96, 56, 56])\n",
      "features[2]          torch.Size([1, 192, 28, 28])\n",
      "features[3]          torch.Size([1, 192, 28, 28])\n",
      "features[4]          torch.Size([1, 384, 14, 14])\n",
      "features[5]          torch.Size([1, 384, 14, 14])\n",
      "features[6]          torch.Size([1, 768, 7, 7])\n",
      "features[7]          torch.Size([1, 768, 7, 7])\n",
      "features             torch.Size([1, 768, 7, 7])\n",
      "avgpool              torch.Size([1, 768, 1, 1])\n",
      "classifier           torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(\"{:20s} {:}\".format(\"input\", input.shape))\n",
    "print(\"{:20s} {:}\".format(\"output\", output.shape))\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "for key, item in activation.items():\n",
    "    print(\"{:20s} {:}\".format(key, item.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary(model, input_size=(3, 224, 224), device=\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.convnext_tiny()\n",
    "\n",
    "ctsrbm_image_transform = torchvision.models.ConvNeXt_Tiny_Weights.DEFAULT.transforms()\n",
    "ctsrbm_image_transform.antialias = True\n",
    "ctsrbm_dataset_dir = os.path.join(pathlib.Path.home(), \"data\", \"DeepFashion\", \"Consumer-to-shop Clothes Retrieval Benchmark\")\n",
    "ctsrbm_dataset = src.datasets.deep_fashion_ctsrbm.ConsToShopClothRetrBmkImageLoader(ctsrbm_dataset_dir, ctsrbm_image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "for idx in [1, 3, 5, 7]:\n",
    "    model.features[idx].register_forward_hook(get_activation('features[{:d}]'.format(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [00:17<00:00, 27.71it/s]\n"
     ]
    }
   ],
   "source": [
    "size_list = list(range(32, 512))\n",
    "feature_1_shape_list = []\n",
    "feature_3_shape_list = []\n",
    "feature_5_shape_list = []\n",
    "feature_7_shape_list = []\n",
    "\n",
    "for size in tqdm(size_list):\n",
    "\n",
    "    input = ctsrbm_dataset[0][0][None, :, :size, :size]\n",
    "    output = model(input)\n",
    "\n",
    "    feature_1_shape_list.append(tuple(activation[\"features[1]\"].shape))\n",
    "    feature_3_shape_list.append(tuple(activation[\"features[3]\"].shape))\n",
    "    feature_5_shape_list.append(tuple(activation[\"features[5]\"].shape))\n",
    "    feature_7_shape_list.append(tuple(activation[\"features[7]\"].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img size | Ftr size 1\n",
      "      32 |          8\n",
      "      36 |          9\n",
      "      40 |         10\n",
      "      44 |         11\n",
      "      48 |         12\n",
      "      52 |         13\n",
      "      56 |         14\n",
      "      60 |         15\n",
      "      64 |         16\n",
      "      68 |         17\n",
      "      72 |         18\n",
      "      76 |         19\n",
      "      80 |         20\n",
      "      84 |         21\n",
      "      88 |         22\n",
      "      92 |         23\n",
      "      96 |         24\n",
      "     100 |         25\n",
      "     104 |         26\n",
      "     108 |         27\n",
      "     112 |         28\n",
      "     116 |         29\n",
      "     120 |         30\n",
      "     124 |         31\n",
      "     128 |         32\n",
      "     132 |         33\n",
      "     136 |         34\n",
      "     140 |         35\n",
      "     144 |         36\n",
      "     148 |         37\n",
      "     152 |         38\n",
      "     156 |         39\n",
      "     160 |         40\n",
      "     164 |         41\n",
      "     168 |         42\n",
      "     172 |         43\n",
      "     176 |         44\n",
      "     180 |         45\n",
      "     184 |         46\n",
      "     188 |         47\n",
      "     192 |         48\n",
      "     196 |         49\n",
      "     200 |         50\n",
      "     204 |         51\n",
      "     208 |         52\n",
      "     212 |         53\n",
      "     216 |         54\n",
      "     220 |         55\n",
      "     224 |         56\n"
     ]
    }
   ],
   "source": [
    "last_perm_size = 0\n",
    "\n",
    "print(\"Img size | Ftr size 1\")\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_1_shape_list[idx][-1]\n",
    "\n",
    "    if last_perm_size < perm_size:\n",
    "        print(\"     {:3d} |        {:3d}\".format(size, perm_size))\n",
    "        last_perm_size = perm_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img size | Ftr size 3\n",
      "      32 |          4\n",
      "      40 |          5\n",
      "      48 |          6\n",
      "      56 |          7\n",
      "      64 |          8\n",
      "      72 |          9\n",
      "      80 |         10\n",
      "      88 |         11\n",
      "      96 |         12\n",
      "     104 |         13\n",
      "     112 |         14\n",
      "     120 |         15\n",
      "     128 |         16\n",
      "     136 |         17\n",
      "     144 |         18\n",
      "     152 |         19\n",
      "     160 |         20\n",
      "     168 |         21\n",
      "     176 |         22\n",
      "     184 |         23\n",
      "     192 |         24\n",
      "     200 |         25\n",
      "     208 |         26\n",
      "     216 |         27\n",
      "     224 |         28\n"
     ]
    }
   ],
   "source": [
    "last_perm_size = 0\n",
    "\n",
    "print(\"Img size | Ftr size 3\")\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_3_shape_list[idx][-1]\n",
    "\n",
    "    if last_perm_size < perm_size:\n",
    "        print(\"     {:3d} |        {:3d}\".format(size, perm_size))\n",
    "        last_perm_size = perm_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img size | Ftr size 5\n",
      "      32 |          2\n",
      "      48 |          3\n",
      "      64 |          4\n",
      "      80 |          5\n",
      "      96 |          6\n",
      "     112 |          7\n",
      "     128 |          8\n",
      "     144 |          9\n",
      "     160 |         10\n",
      "     176 |         11\n",
      "     192 |         12\n",
      "     208 |         13\n",
      "     224 |         14\n"
     ]
    }
   ],
   "source": [
    "last_perm_size = 0\n",
    "\n",
    "print(\"Img size | Ftr size 5\")\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_5_shape_list[idx][-1]\n",
    "\n",
    "    if last_perm_size < perm_size:\n",
    "        print(\"     {:3d} |        {:3d}\".format(size, perm_size))\n",
    "        last_perm_size = perm_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img size | Ftr size 7\n",
      "      32 |          1\n",
      "      64 |          2\n",
      "      96 |          3\n",
      "     128 |          4\n",
      "     160 |          5\n",
      "     192 |          6\n",
      "     224 |          7\n"
     ]
    }
   ],
   "source": [
    "last_perm_size = 0\n",
    "\n",
    "print(\"Img size | Ftr size 7\")\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_7_shape_list[idx][-1]\n",
    "\n",
    "    if last_perm_size < perm_size:\n",
    "        print(\"     {:3d} |        {:3d}\".format(size, perm_size))\n",
    "        last_perm_size = perm_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_1_shape_formula(size):\n",
    "    return min(size // 4, 56)\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_1_shape_list[idx][-1]\n",
    "    pred_perm_size = feature_1_shape_formula(size)\n",
    "\n",
    "    if perm_size != pred_perm_size:\n",
    "        print(\"ERROR: size = {:4d} | perm_size = {:4d} | pred_perm_size = {:4d}\".format(\n",
    "            size,\n",
    "            perm_size,\n",
    "            pred_perm_size\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_3_shape_formula(size):\n",
    "    return min(size // 8, 28)\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_3_shape_list[idx][-1]\n",
    "    pred_perm_size = feature_3_shape_formula(size)\n",
    "\n",
    "    if perm_size != pred_perm_size:\n",
    "        print(\"ERROR: size = {:4d} | perm_size = {:4d} | pred_perm_size = {:4d}\".format(\n",
    "            size,\n",
    "            perm_size,\n",
    "            pred_perm_size\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_5_shape_formula(size):\n",
    "    return min(size // 16, 14)\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_5_shape_list[idx][-1]\n",
    "    pred_perm_size = feature_5_shape_formula(size)\n",
    "\n",
    "    if perm_size != pred_perm_size:\n",
    "        print(\"ERROR: size = {:4d} | perm_size = {:4d} | pred_perm_size = {:4d}\".format(\n",
    "            size,\n",
    "            perm_size,\n",
    "            pred_perm_size\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_7_shape_formula(size):\n",
    "    return min(size // 32, 7)\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_7_shape_list[idx][-1]\n",
    "    pred_perm_size = feature_7_shape_formula(size)\n",
    "\n",
    "    if perm_size != pred_perm_size:\n",
    "        print(\"ERROR: size = {:4d} | perm_size = {:4d} | pred_perm_size = {:4d}\".format(\n",
    "            size,\n",
    "            perm_size,\n",
    "            pred_perm_size\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "649142fb4cdab8a2d2387ea4a1c8e262f08b2b20e4af0e114d36ea602bf8b868"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
