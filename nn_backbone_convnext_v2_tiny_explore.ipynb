{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision import models\n",
    "import transformers\n",
    "from transformers import ConvNextV2Model, AutoImageProcessor\n",
    "\n",
    "import src.datasets.deep_fashion_ctsrbm\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import src.comps.backbones_cnn_pyramid\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNextV2Model.from_pretrained(\"facebook/convnextv2-tiny-22k-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"misc/convnext_v2_tiny_model_arch.txt\", \"w\") as out_file:\n",
    "    print(model, file=out_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNextV2Model.from_pretrained(\"facebook/convnextv2-tiny-22k-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctsrbm_image_transform = AutoImageProcessor.from_pretrained(\"facebook/convnextv2-tiny-22k-224\")\n",
    "ctsrbm_image_transform_corr = lambda ten: (ctsrbm_image_transform(ten, return_tensors=\"pt\").pixel_values)\n",
    "\n",
    "ctsrbm_dataset_dir = os.path.join(pathlib.Path.home(), \"data\", \"DeepFashion\", \"Consumer-to-shop Clothes Retrieval Benchmark\")\n",
    "ctsrbm_dataset = src.datasets.deep_fashion_ctsrbm.ConsToShopClothRetrBmkImageLoader(ctsrbm_dataset_dir, ctsrbm_image_transform_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNextImageProcessor {\n",
       "  \"crop_pct\": 0.875,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"ConvNextImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"shortest_edge\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctsrbm_image_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_item = ctsrbm_dataset[0]\n",
    "\n",
    "img_tensor = dataset_item[0]\n",
    "item_id_tensor = dataset_item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tensor = model(img_tensor).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 768, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor.shape)\n",
    "print(feature_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f4790d7ed60>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output\n",
    "    return hook\n",
    "\n",
    "model = ConvNextV2Model.from_pretrained(\"facebook/convnextv2-tiny-22k-224\")\n",
    "\n",
    "model.encoder.stages[0].register_forward_hook(get_activation('encoder.stages[0]'))\n",
    "model.encoder.stages[1].register_forward_hook(get_activation('encoder.stages[1]'))\n",
    "model.encoder.stages[2].register_forward_hook(get_activation('encoder.stages[2]'))\n",
    "model.encoder.stages[3].register_forward_hook(get_activation('encoder.stages[3]'))\n",
    "model.encoder.register_forward_hook(get_activation('encoder'))\n",
    "model.layernorm.register_forward_hook(get_activation('layernorm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_item = ctsrbm_dataset[0]\n",
    "\n",
    "img_tensor = dataset_item[0]\n",
    "item_id_tensor = dataset_item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tensor = model(img_tensor).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_tensor           torch.Size([1, 3, 224, 224])\n",
      "---\n",
      "encoder.stages[0]    torch.Size([1, 96, 56, 56])\n",
      "encoder.stages[1]    torch.Size([1, 192, 28, 28])\n",
      "encoder.stages[2]    torch.Size([1, 384, 14, 14])\n",
      "encoder.stages[3]    torch.Size([1, 768, 7, 7])\n",
      "encoder              torch.Size([1, 768, 7, 7])\n",
      "layernorm            torch.Size([1, 768])\n",
      "---\n",
      "feature_tensor       torch.Size([1, 768, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "print(\"{:20s} {:}\".format(\"img_tensor\", img_tensor.shape))\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "for key, item in activation.items():\n",
    "    if key in [\"encoder\"]:\n",
    "        print(\"{:20s} {:}\".format(key, item.last_hidden_state.shape))\n",
    "    else:\n",
    "        print(\"{:20s} {:}\".format(key, item.shape))\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "print(\"{:20s} {:}\".format(\"feature_tensor\", feature_tensor.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctsrbm_image_transform = AutoImageProcessor.from_pretrained(\"facebook/convnextv2-tiny-22k-224\")\n",
    "ctsrbm_image_transform_corr = lambda ten: (ctsrbm_image_transform(ten, return_tensors=\"pt\").pixel_values)\n",
    "\n",
    "ctsrbm_dataset_dir = os.path.join(pathlib.Path.home(), \"data\", \"DeepFashion\", \"Consumer-to-shop Clothes Retrieval Benchmark\")\n",
    "ctsrbm_dataset = src.datasets.deep_fashion_ctsrbm.ConsToShopClothRetrBmkImageLoader(ctsrbm_dataset_dir, ctsrbm_image_transform_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f47f258c310>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output\n",
    "    return hook\n",
    "\n",
    "model = ConvNextV2Model.from_pretrained(\"facebook/convnextv2-tiny-22k-224\")\n",
    "\n",
    "model.encoder.stages[0].register_forward_hook(get_activation('encoder.stages[0]'))\n",
    "model.encoder.stages[1].register_forward_hook(get_activation('encoder.stages[1]'))\n",
    "model.encoder.stages[2].register_forward_hook(get_activation('encoder.stages[2]'))\n",
    "model.encoder.stages[3].register_forward_hook(get_activation('encoder.stages[3]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [00:35<00:00, 13.41it/s]\n"
     ]
    }
   ],
   "source": [
    "size_list = list(range(32, 512))\n",
    "feature_1_shape_list = []\n",
    "feature_2_shape_list = []\n",
    "feature_3_shape_list = []\n",
    "feature_4_shape_list = []\n",
    "\n",
    "for size in tqdm(size_list):\n",
    "\n",
    "    input = torch.empty(1, 3, size, size)\n",
    "    output = model(input)\n",
    "\n",
    "    feature_1_shape_list.append(tuple(activation[\"encoder.stages[0]\"].shape))\n",
    "    feature_2_shape_list.append(tuple(activation[\"encoder.stages[1]\"].shape))\n",
    "    feature_3_shape_list.append(tuple(activation[\"encoder.stages[2]\"].shape))\n",
    "    feature_4_shape_list.append(tuple(activation[\"encoder.stages[3]\"].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img size | Ftr size 1\n",
      "      32 |          8\n",
      "      36 |          9\n",
      "      40 |         10\n",
      "      44 |         11\n",
      "      48 |         12\n",
      "      52 |         13\n",
      "      56 |         14\n",
      "      60 |         15\n",
      "      64 |         16\n",
      "      68 |         17\n",
      "      72 |         18\n",
      "      76 |         19\n",
      "      80 |         20\n",
      "      84 |         21\n",
      "      88 |         22\n",
      "      92 |         23\n",
      "      96 |         24\n",
      "     100 |         25\n",
      "     104 |         26\n",
      "     108 |         27\n",
      "     112 |         28\n",
      "     116 |         29\n",
      "     120 |         30\n",
      "     124 |         31\n",
      "     128 |         32\n",
      "     132 |         33\n",
      "     136 |         34\n",
      "     140 |         35\n",
      "     144 |         36\n",
      "     148 |         37\n",
      "     152 |         38\n",
      "     156 |         39\n",
      "     160 |         40\n",
      "     164 |         41\n",
      "     168 |         42\n",
      "     172 |         43\n",
      "     176 |         44\n",
      "     180 |         45\n",
      "     184 |         46\n",
      "     188 |         47\n",
      "     192 |         48\n",
      "     196 |         49\n",
      "     200 |         50\n",
      "     204 |         51\n",
      "     208 |         52\n",
      "     212 |         53\n",
      "     216 |         54\n",
      "     220 |         55\n",
      "     224 |         56\n",
      "     228 |         57\n",
      "     232 |         58\n",
      "     236 |         59\n",
      "     240 |         60\n",
      "     244 |         61\n",
      "     248 |         62\n",
      "     252 |         63\n",
      "     256 |         64\n",
      "     260 |         65\n",
      "     264 |         66\n",
      "     268 |         67\n",
      "     272 |         68\n",
      "     276 |         69\n",
      "     280 |         70\n",
      "     284 |         71\n",
      "     288 |         72\n",
      "     292 |         73\n",
      "     296 |         74\n",
      "     300 |         75\n",
      "     304 |         76\n",
      "     308 |         77\n",
      "     312 |         78\n",
      "     316 |         79\n",
      "     320 |         80\n",
      "     324 |         81\n",
      "     328 |         82\n",
      "     332 |         83\n",
      "     336 |         84\n",
      "     340 |         85\n",
      "     344 |         86\n",
      "     348 |         87\n",
      "     352 |         88\n",
      "     356 |         89\n",
      "     360 |         90\n",
      "     364 |         91\n",
      "     368 |         92\n",
      "     372 |         93\n",
      "     376 |         94\n",
      "     380 |         95\n",
      "     384 |         96\n",
      "     388 |         97\n",
      "     392 |         98\n",
      "     396 |         99\n",
      "     400 |        100\n",
      "     404 |        101\n",
      "     408 |        102\n",
      "     412 |        103\n",
      "     416 |        104\n",
      "     420 |        105\n",
      "     424 |        106\n",
      "     428 |        107\n",
      "     432 |        108\n",
      "     436 |        109\n",
      "     440 |        110\n",
      "     444 |        111\n",
      "     448 |        112\n",
      "     452 |        113\n",
      "     456 |        114\n",
      "     460 |        115\n",
      "     464 |        116\n",
      "     468 |        117\n",
      "     472 |        118\n",
      "     476 |        119\n",
      "     480 |        120\n",
      "     484 |        121\n",
      "     488 |        122\n",
      "     492 |        123\n",
      "     496 |        124\n",
      "     500 |        125\n",
      "     504 |        126\n",
      "     508 |        127\n"
     ]
    }
   ],
   "source": [
    "last_perm_size = 0\n",
    "\n",
    "print(\"Img size | Ftr size 1\")\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_1_shape_list[idx][-1]\n",
    "\n",
    "    if last_perm_size < perm_size:\n",
    "        print(\"     {:3d} |        {:3d}\".format(size, perm_size))\n",
    "        last_perm_size = perm_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img size | Ftr size 2\n",
      "      32 |          4\n",
      "      40 |          5\n",
      "      48 |          6\n",
      "      56 |          7\n",
      "      64 |          8\n",
      "      72 |          9\n",
      "      80 |         10\n",
      "      88 |         11\n",
      "      96 |         12\n",
      "     104 |         13\n",
      "     112 |         14\n",
      "     120 |         15\n",
      "     128 |         16\n",
      "     136 |         17\n",
      "     144 |         18\n",
      "     152 |         19\n",
      "     160 |         20\n",
      "     168 |         21\n",
      "     176 |         22\n",
      "     184 |         23\n",
      "     192 |         24\n",
      "     200 |         25\n",
      "     208 |         26\n",
      "     216 |         27\n",
      "     224 |         28\n",
      "     232 |         29\n",
      "     240 |         30\n",
      "     248 |         31\n",
      "     256 |         32\n",
      "     264 |         33\n",
      "     272 |         34\n",
      "     280 |         35\n",
      "     288 |         36\n",
      "     296 |         37\n",
      "     304 |         38\n",
      "     312 |         39\n",
      "     320 |         40\n",
      "     328 |         41\n",
      "     336 |         42\n",
      "     344 |         43\n",
      "     352 |         44\n",
      "     360 |         45\n",
      "     368 |         46\n",
      "     376 |         47\n",
      "     384 |         48\n",
      "     392 |         49\n",
      "     400 |         50\n",
      "     408 |         51\n",
      "     416 |         52\n",
      "     424 |         53\n",
      "     432 |         54\n",
      "     440 |         55\n",
      "     448 |         56\n",
      "     456 |         57\n",
      "     464 |         58\n",
      "     472 |         59\n",
      "     480 |         60\n",
      "     488 |         61\n",
      "     496 |         62\n",
      "     504 |         63\n"
     ]
    }
   ],
   "source": [
    "last_perm_size = 0\n",
    "\n",
    "print(\"Img size | Ftr size 2\")\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_2_shape_list[idx][-1]\n",
    "\n",
    "    if last_perm_size < perm_size:\n",
    "        print(\"     {:3d} |        {:3d}\".format(size, perm_size))\n",
    "        last_perm_size = perm_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img size | Ftr size 3\n",
      "      32 |          2\n",
      "      48 |          3\n",
      "      64 |          4\n",
      "      80 |          5\n",
      "      96 |          6\n",
      "     112 |          7\n",
      "     128 |          8\n",
      "     144 |          9\n",
      "     160 |         10\n",
      "     176 |         11\n",
      "     192 |         12\n",
      "     208 |         13\n",
      "     224 |         14\n",
      "     240 |         15\n",
      "     256 |         16\n",
      "     272 |         17\n",
      "     288 |         18\n",
      "     304 |         19\n",
      "     320 |         20\n",
      "     336 |         21\n",
      "     352 |         22\n",
      "     368 |         23\n",
      "     384 |         24\n",
      "     400 |         25\n",
      "     416 |         26\n",
      "     432 |         27\n",
      "     448 |         28\n",
      "     464 |         29\n",
      "     480 |         30\n",
      "     496 |         31\n"
     ]
    }
   ],
   "source": [
    "last_perm_size = 0\n",
    "\n",
    "print(\"Img size | Ftr size 3\")\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_3_shape_list[idx][-1]\n",
    "\n",
    "    if last_perm_size < perm_size:\n",
    "        print(\"     {:3d} |        {:3d}\".format(size, perm_size))\n",
    "        last_perm_size = perm_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img size | Ftr size 4\n",
      "      32 |          1\n",
      "      64 |          2\n",
      "      96 |          3\n",
      "     128 |          4\n",
      "     160 |          5\n",
      "     192 |          6\n",
      "     224 |          7\n",
      "     256 |          8\n",
      "     288 |          9\n",
      "     320 |         10\n",
      "     352 |         11\n",
      "     384 |         12\n",
      "     416 |         13\n",
      "     448 |         14\n",
      "     480 |         15\n"
     ]
    }
   ],
   "source": [
    "last_perm_size = 0\n",
    "\n",
    "print(\"Img size | Ftr size 4\")\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_4_shape_list[idx][-1]\n",
    "\n",
    "    if last_perm_size < perm_size:\n",
    "        print(\"     {:3d} |        {:3d}\".format(size, perm_size))\n",
    "        last_perm_size = perm_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_1_shape_formula(size):\n",
    "    return (size // 4)\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_1_shape_list[idx][-1]\n",
    "    pred_perm_size = feature_1_shape_formula(size)\n",
    "\n",
    "    if perm_size != pred_perm_size:\n",
    "        print(\"ERROR: size = {:4d} | perm_size = {:4d} | pred_perm_size = {:4d}\".format(\n",
    "            size,\n",
    "            perm_size,\n",
    "            pred_perm_size\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_2_shape_formula(size):\n",
    "    return (size // 8)\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_2_shape_list[idx][-1]\n",
    "    pred_perm_size = feature_2_shape_formula(size)\n",
    "\n",
    "    if perm_size != pred_perm_size:\n",
    "        print(\"ERROR: size = {:4d} | perm_size = {:4d} | pred_perm_size = {:4d}\".format(\n",
    "            size,\n",
    "            perm_size,\n",
    "            pred_perm_size\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_3_shape_formula(size):\n",
    "    return (size // 16)\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_3_shape_list[idx][-1]\n",
    "    pred_perm_size = feature_3_shape_formula(size)\n",
    "\n",
    "    if perm_size != pred_perm_size:\n",
    "        print(\"ERROR: size = {:4d} | perm_size = {:4d} | pred_perm_size = {:4d}\".format(\n",
    "            size,\n",
    "            perm_size,\n",
    "            pred_perm_size\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_4_shape_formula(size):\n",
    "    return (size // 32)\n",
    "\n",
    "for idx, size in enumerate(size_list):\n",
    "\n",
    "    perm_size = feature_4_shape_list[idx][-1]\n",
    "    pred_perm_size = feature_4_shape_formula(size)\n",
    "\n",
    "    if perm_size != pred_perm_size:\n",
    "        print(\"ERROR: size = {:4d} | perm_size = {:4d} | pred_perm_size = {:4d}\".format(\n",
    "            size,\n",
    "            perm_size,\n",
    "            pred_perm_size\n",
    "        ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = src.comps.backbones_cnn_pyramid.ConvNeXtV2TinyMultilevelBackbone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctsrbm_image_transform = model.get_image_transform()\n",
    "\n",
    "ctsrbm_dataset_dir = os.path.join(pathlib.Path.home(), \"data\", \"DeepFashion\", \"Consumer-to-shop Clothes Retrieval Benchmark\")\n",
    "ctsrbm_dataset = src.datasets.deep_fashion_ctsrbm.ConsToShopClothRetrBmkImageLoader(ctsrbm_dataset_dir, ctsrbm_image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_item = ctsrbm_dataset[0]\n",
    "\n",
    "img_tensor = dataset_item[0]\n",
    "item_id_tensor = dataset_item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tensors = model(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 56, 56])\n",
      "torch.Size([1, 192, 28, 28])\n",
      "torch.Size([1, 384, 14, 14])\n",
      "torch.Size([1, 768, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "print(feature_tensors[0].shape)\n",
    "print(feature_tensors[1].shape)\n",
    "print(feature_tensors[2].shape)\n",
    "print(feature_tensors[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 56, 56]           4,704\n",
      "ConvNextV2LayerNorm-2           [-1, 96, 56, 56]             192\n",
      "ConvNextV2Embeddings-3           [-1, 96, 56, 56]               0\n",
      "          Identity-4           [-1, 96, 56, 56]               0\n",
      "            Conv2d-5           [-1, 96, 56, 56]           4,800\n",
      "ConvNextV2LayerNorm-6           [-1, 56, 56, 96]             192\n",
      "            Linear-7          [-1, 56, 56, 384]          37,248\n",
      "    GELUActivation-8          [-1, 56, 56, 384]               0\n",
      "     ConvNextV2GRN-9          [-1, 56, 56, 384]             768\n",
      "           Linear-10           [-1, 56, 56, 96]          36,960\n",
      "         Identity-11           [-1, 96, 56, 56]               0\n",
      "  ConvNextV2Layer-12           [-1, 96, 56, 56]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]           4,800\n",
      "ConvNextV2LayerNorm-14           [-1, 56, 56, 96]             192\n",
      "           Linear-15          [-1, 56, 56, 384]          37,248\n",
      "   GELUActivation-16          [-1, 56, 56, 384]               0\n",
      "    ConvNextV2GRN-17          [-1, 56, 56, 384]             768\n",
      "           Linear-18           [-1, 56, 56, 96]          36,960\n",
      "         Identity-19           [-1, 96, 56, 56]               0\n",
      "  ConvNextV2Layer-20           [-1, 96, 56, 56]               0\n",
      "           Conv2d-21           [-1, 96, 56, 56]           4,800\n",
      "ConvNextV2LayerNorm-22           [-1, 56, 56, 96]             192\n",
      "           Linear-23          [-1, 56, 56, 384]          37,248\n",
      "   GELUActivation-24          [-1, 56, 56, 384]               0\n",
      "    ConvNextV2GRN-25          [-1, 56, 56, 384]             768\n",
      "           Linear-26           [-1, 56, 56, 96]          36,960\n",
      "         Identity-27           [-1, 96, 56, 56]               0\n",
      "  ConvNextV2Layer-28           [-1, 96, 56, 56]               0\n",
      "  ConvNextV2Stage-29           [-1, 96, 56, 56]               0\n",
      "ConvNextV2LayerNorm-30           [-1, 96, 56, 56]             192\n",
      "           Conv2d-31          [-1, 192, 28, 28]          73,920\n",
      "           Conv2d-32          [-1, 192, 28, 28]           9,600\n",
      "ConvNextV2LayerNorm-33          [-1, 28, 28, 192]             384\n",
      "           Linear-34          [-1, 28, 28, 768]         148,224\n",
      "   GELUActivation-35          [-1, 28, 28, 768]               0\n",
      "    ConvNextV2GRN-36          [-1, 28, 28, 768]           1,536\n",
      "           Linear-37          [-1, 28, 28, 192]         147,648\n",
      "         Identity-38          [-1, 192, 28, 28]               0\n",
      "  ConvNextV2Layer-39          [-1, 192, 28, 28]               0\n",
      "           Conv2d-40          [-1, 192, 28, 28]           9,600\n",
      "ConvNextV2LayerNorm-41          [-1, 28, 28, 192]             384\n",
      "           Linear-42          [-1, 28, 28, 768]         148,224\n",
      "   GELUActivation-43          [-1, 28, 28, 768]               0\n",
      "    ConvNextV2GRN-44          [-1, 28, 28, 768]           1,536\n",
      "           Linear-45          [-1, 28, 28, 192]         147,648\n",
      "         Identity-46          [-1, 192, 28, 28]               0\n",
      "  ConvNextV2Layer-47          [-1, 192, 28, 28]               0\n",
      "           Conv2d-48          [-1, 192, 28, 28]           9,600\n",
      "ConvNextV2LayerNorm-49          [-1, 28, 28, 192]             384\n",
      "           Linear-50          [-1, 28, 28, 768]         148,224\n",
      "   GELUActivation-51          [-1, 28, 28, 768]               0\n",
      "    ConvNextV2GRN-52          [-1, 28, 28, 768]           1,536\n",
      "           Linear-53          [-1, 28, 28, 192]         147,648\n",
      "         Identity-54          [-1, 192, 28, 28]               0\n",
      "  ConvNextV2Layer-55          [-1, 192, 28, 28]               0\n",
      "  ConvNextV2Stage-56          [-1, 192, 28, 28]               0\n",
      "ConvNextV2LayerNorm-57          [-1, 192, 28, 28]             384\n",
      "           Conv2d-58          [-1, 384, 14, 14]         295,296\n",
      "           Conv2d-59          [-1, 384, 14, 14]          19,200\n",
      "ConvNextV2LayerNorm-60          [-1, 14, 14, 384]             768\n",
      "           Linear-61         [-1, 14, 14, 1536]         591,360\n",
      "   GELUActivation-62         [-1, 14, 14, 1536]               0\n",
      "    ConvNextV2GRN-63         [-1, 14, 14, 1536]           3,072\n",
      "           Linear-64          [-1, 14, 14, 384]         590,208\n",
      "         Identity-65          [-1, 384, 14, 14]               0\n",
      "  ConvNextV2Layer-66          [-1, 384, 14, 14]               0\n",
      "           Conv2d-67          [-1, 384, 14, 14]          19,200\n",
      "ConvNextV2LayerNorm-68          [-1, 14, 14, 384]             768\n",
      "           Linear-69         [-1, 14, 14, 1536]         591,360\n",
      "   GELUActivation-70         [-1, 14, 14, 1536]               0\n",
      "    ConvNextV2GRN-71         [-1, 14, 14, 1536]           3,072\n",
      "           Linear-72          [-1, 14, 14, 384]         590,208\n",
      "         Identity-73          [-1, 384, 14, 14]               0\n",
      "  ConvNextV2Layer-74          [-1, 384, 14, 14]               0\n",
      "           Conv2d-75          [-1, 384, 14, 14]          19,200\n",
      "ConvNextV2LayerNorm-76          [-1, 14, 14, 384]             768\n",
      "           Linear-77         [-1, 14, 14, 1536]         591,360\n",
      "   GELUActivation-78         [-1, 14, 14, 1536]               0\n",
      "    ConvNextV2GRN-79         [-1, 14, 14, 1536]           3,072\n",
      "           Linear-80          [-1, 14, 14, 384]         590,208\n",
      "         Identity-81          [-1, 384, 14, 14]               0\n",
      "  ConvNextV2Layer-82          [-1, 384, 14, 14]               0\n",
      "           Conv2d-83          [-1, 384, 14, 14]          19,200\n",
      "ConvNextV2LayerNorm-84          [-1, 14, 14, 384]             768\n",
      "           Linear-85         [-1, 14, 14, 1536]         591,360\n",
      "   GELUActivation-86         [-1, 14, 14, 1536]               0\n",
      "    ConvNextV2GRN-87         [-1, 14, 14, 1536]           3,072\n",
      "           Linear-88          [-1, 14, 14, 384]         590,208\n",
      "         Identity-89          [-1, 384, 14, 14]               0\n",
      "  ConvNextV2Layer-90          [-1, 384, 14, 14]               0\n",
      "           Conv2d-91          [-1, 384, 14, 14]          19,200\n",
      "ConvNextV2LayerNorm-92          [-1, 14, 14, 384]             768\n",
      "           Linear-93         [-1, 14, 14, 1536]         591,360\n",
      "   GELUActivation-94         [-1, 14, 14, 1536]               0\n",
      "    ConvNextV2GRN-95         [-1, 14, 14, 1536]           3,072\n",
      "           Linear-96          [-1, 14, 14, 384]         590,208\n",
      "         Identity-97          [-1, 384, 14, 14]               0\n",
      "  ConvNextV2Layer-98          [-1, 384, 14, 14]               0\n",
      "           Conv2d-99          [-1, 384, 14, 14]          19,200\n",
      "ConvNextV2LayerNorm-100          [-1, 14, 14, 384]             768\n",
      "          Linear-101         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-102         [-1, 14, 14, 1536]               0\n",
      "   ConvNextV2GRN-103         [-1, 14, 14, 1536]           3,072\n",
      "          Linear-104          [-1, 14, 14, 384]         590,208\n",
      "        Identity-105          [-1, 384, 14, 14]               0\n",
      " ConvNextV2Layer-106          [-1, 384, 14, 14]               0\n",
      "          Conv2d-107          [-1, 384, 14, 14]          19,200\n",
      "ConvNextV2LayerNorm-108          [-1, 14, 14, 384]             768\n",
      "          Linear-109         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-110         [-1, 14, 14, 1536]               0\n",
      "   ConvNextV2GRN-111         [-1, 14, 14, 1536]           3,072\n",
      "          Linear-112          [-1, 14, 14, 384]         590,208\n",
      "        Identity-113          [-1, 384, 14, 14]               0\n",
      " ConvNextV2Layer-114          [-1, 384, 14, 14]               0\n",
      "          Conv2d-115          [-1, 384, 14, 14]          19,200\n",
      "ConvNextV2LayerNorm-116          [-1, 14, 14, 384]             768\n",
      "          Linear-117         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-118         [-1, 14, 14, 1536]               0\n",
      "   ConvNextV2GRN-119         [-1, 14, 14, 1536]           3,072\n",
      "          Linear-120          [-1, 14, 14, 384]         590,208\n",
      "        Identity-121          [-1, 384, 14, 14]               0\n",
      " ConvNextV2Layer-122          [-1, 384, 14, 14]               0\n",
      "          Conv2d-123          [-1, 384, 14, 14]          19,200\n",
      "ConvNextV2LayerNorm-124          [-1, 14, 14, 384]             768\n",
      "          Linear-125         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-126         [-1, 14, 14, 1536]               0\n",
      "   ConvNextV2GRN-127         [-1, 14, 14, 1536]           3,072\n",
      "          Linear-128          [-1, 14, 14, 384]         590,208\n",
      "        Identity-129          [-1, 384, 14, 14]               0\n",
      " ConvNextV2Layer-130          [-1, 384, 14, 14]               0\n",
      " ConvNextV2Stage-131          [-1, 384, 14, 14]               0\n",
      "ConvNextV2LayerNorm-132          [-1, 384, 14, 14]             768\n",
      "          Conv2d-133            [-1, 768, 7, 7]       1,180,416\n",
      "          Conv2d-134            [-1, 768, 7, 7]          38,400\n",
      "ConvNextV2LayerNorm-135            [-1, 7, 7, 768]           1,536\n",
      "          Linear-136           [-1, 7, 7, 3072]       2,362,368\n",
      "  GELUActivation-137           [-1, 7, 7, 3072]               0\n",
      "   ConvNextV2GRN-138           [-1, 7, 7, 3072]           6,144\n",
      "          Linear-139            [-1, 7, 7, 768]       2,360,064\n",
      "        Identity-140            [-1, 768, 7, 7]               0\n",
      " ConvNextV2Layer-141            [-1, 768, 7, 7]               0\n",
      "          Conv2d-142            [-1, 768, 7, 7]          38,400\n",
      "ConvNextV2LayerNorm-143            [-1, 7, 7, 768]           1,536\n",
      "          Linear-144           [-1, 7, 7, 3072]       2,362,368\n",
      "  GELUActivation-145           [-1, 7, 7, 3072]               0\n",
      "   ConvNextV2GRN-146           [-1, 7, 7, 3072]           6,144\n",
      "          Linear-147            [-1, 7, 7, 768]       2,360,064\n",
      "        Identity-148            [-1, 768, 7, 7]               0\n",
      " ConvNextV2Layer-149            [-1, 768, 7, 7]               0\n",
      "          Conv2d-150            [-1, 768, 7, 7]          38,400\n",
      "ConvNextV2LayerNorm-151            [-1, 7, 7, 768]           1,536\n",
      "          Linear-152           [-1, 7, 7, 3072]       2,362,368\n",
      "  GELUActivation-153           [-1, 7, 7, 3072]               0\n",
      "   ConvNextV2GRN-154           [-1, 7, 7, 3072]           6,144\n",
      "          Linear-155            [-1, 7, 7, 768]       2,360,064\n",
      "        Identity-156            [-1, 768, 7, 7]               0\n",
      " ConvNextV2Layer-157            [-1, 768, 7, 7]               0\n",
      " ConvNextV2Stage-158            [-1, 768, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 27,864,960\n",
      "Trainable params: 27,864,960\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 297.73\n",
      "Params size (MB): 106.30\n",
      "Estimated Total Size (MB): 404.60\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 224, 224), device=\"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "649142fb4cdab8a2d2387ea4a1c8e262f08b2b20e4af0e114d36ea602bf8b868"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
