{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import src.utils.tensor\n",
    "import src.utils.module\n",
    "import src.utils.comps\n",
    "\n",
    "import src.comps.backbones_trf\n",
    "import src.comps.backbones_trf_pyramid\n",
    "\n",
    "import src.comps.heads_pyramid_2\n",
    "import src.comps.heads_glam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone params:      27,707,950\n"
     ]
    }
   ],
   "source": [
    "backbone = src.comps.backbones_trf_pyramid.GCVitTinyMultilevelBackbone(\n",
    "    img_size=224\n",
    ")\n",
    "\n",
    "print(\"Backbone params: {:15,d}\".format(src.utils.module.get_num_params(backbone)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone params:      27,709,870\n"
     ]
    }
   ],
   "source": [
    "backbone = src.comps.backbones_trf_pyramid.GCVitTinyMultilevelBackbone(\n",
    "    img_size=224,\n",
    "    with_layernorm=True\n",
    ")\n",
    "\n",
    "print(\"Backbone params: {:15,d}\".format(src.utils.module.get_num_params(backbone)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = src.comps.backbones_trf_pyramid.GCVitTinyMultilevelBackbone(\n",
    "    img_size=224\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Output tensor\n",
      "shape:  torch.Size([960])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  3.82 KiB\n",
      "\n",
      "Backbone params:      27,709,870\n",
      "Head params:                   0\n"
     ]
    }
   ],
   "source": [
    "head = src.comps.heads_pyramid_2.RetrievalHeadPyramidTopDownInstantSimple2(\n",
    "    feat_shapes=backbone.feature_shapes,\n",
    "    in_feat_idxs=[0, 1, 2, 3],\n",
    "    emb_size=960,\n",
    "    conv1_groups=None\n",
    ")\n",
    "\n",
    "model = torch.nn.Sequential(backbone, head)\n",
    "\n",
    "#\n",
    "\n",
    "input_tensor = torch.rand(1, 3, 224, 224)\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(output_tensor, name=\"Output tensor\")\n",
    "print()\n",
    "\n",
    "print(\"Backbone params: {:15,d}\".format(src.utils.module.get_num_params(backbone)))\n",
    "print(\"Head params:     {:15,d}\".format(src.utils.module.get_num_params(head)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Output tensor\n",
      "shape:  torch.Size([512])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  2.07 KiB\n",
      "\n",
      "Backbone params:      27,709,870\n",
      "Head params:                   0\n"
     ]
    }
   ],
   "source": [
    "head = src.comps.heads_pyramid_2.RetrievalHeadPyramidTopDownInstantSimple2(\n",
    "    feat_shapes=backbone.feature_shapes,\n",
    "    in_feat_idxs=[3],\n",
    "    emb_size=512,\n",
    "    conv1_groups=None\n",
    ")\n",
    "\n",
    "model = torch.nn.Sequential(backbone, head)\n",
    "\n",
    "#\n",
    "\n",
    "input_tensor = torch.rand(1, 3, 224, 224)\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(output_tensor, name=\"Output tensor\")\n",
    "print()\n",
    "\n",
    "print(\"Backbone params: {:15,d}\".format(src.utils.module.get_num_params(backbone)))\n",
    "print(\"Head params:     {:15,d}\".format(src.utils.module.get_num_params(head)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Output tensor\n",
      "shape:  torch.Size([960])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  3.82 KiB\n",
      "\n",
      "Backbone params:      27,709,870\n",
      "Head params:             922,560\n"
     ]
    }
   ],
   "source": [
    "head = src.comps.heads_pyramid_2.RetrievalHeadPyramidTopDownInstantSimple2(\n",
    "    feat_shapes=backbone.feature_shapes,\n",
    "    in_feat_idxs=[0, 1, 2, 3],\n",
    "    emb_size=960,\n",
    "    conv1_groups=1\n",
    ")\n",
    "\n",
    "model = torch.nn.Sequential(backbone, head)\n",
    "\n",
    "#\n",
    "\n",
    "input_tensor = torch.rand(1, 3, 224, 224)\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(output_tensor, name=\"Output tensor\")\n",
    "print()\n",
    "\n",
    "print(\"Backbone params: {:15,d}\".format(src.utils.module.get_num_params(backbone)))\n",
    "print(\"Head params:     {:15,d}\".format(src.utils.module.get_num_params(head)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Output tensor\n",
      "shape:  torch.Size([512])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  2.07 KiB\n",
      "\n",
      "Backbone params:      27,709,870\n",
      "Head params:             262,656\n"
     ]
    }
   ],
   "source": [
    "head = src.comps.heads_pyramid_2.RetrievalHeadPyramidTopDownInstantSimple2(\n",
    "    feat_shapes=backbone.feature_shapes,\n",
    "    in_feat_idxs=[3],\n",
    "    emb_size=512,\n",
    "    conv1_groups=1\n",
    ")\n",
    "\n",
    "model = torch.nn.Sequential(backbone, head)\n",
    "\n",
    "#\n",
    "\n",
    "input_tensor = torch.rand(1, 3, 224, 224)\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(output_tensor, name=\"Output tensor\")\n",
    "print()\n",
    "\n",
    "print(\"Backbone params: {:15,d}\".format(src.utils.module.get_num_params(backbone)))\n",
    "print(\"Head params:     {:15,d}\".format(src.utils.module.get_num_params(head)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Output tensor\n",
      "shape:  torch.Size([512])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  2.07 KiB\n",
      "\n",
      "Backbone params:      27,709,870\n",
      "Head params:           2,428,172\n"
     ]
    }
   ],
   "source": [
    "head = src.comps.heads_glam.RetrievalGLAMHeadPyramidTopDownInstantSimple(\n",
    "    feat_shapes=backbone.feature_shapes,\n",
    "    in_feat_idxs=[3],\n",
    "    emb_size=512,\n",
    "    glam_int_channels_list=[None, None, None, 256],\n",
    "    conv1_groups=None\n",
    ")\n",
    "\n",
    "model = torch.nn.Sequential(backbone, head)\n",
    "\n",
    "#\n",
    "\n",
    "input_tensor = torch.rand(1, 3, 224, 224)\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(output_tensor, name=\"Output tensor\")\n",
    "print()\n",
    "\n",
    "print(\"Backbone params: {:15,d}\".format(src.utils.module.get_num_params(backbone)))\n",
    "print(\"Head params:     {:15,d}\".format(src.utils.module.get_num_params(head)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Output tensor\n",
      "shape:  torch.Size([960])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  3.82 KiB\n",
      "\n",
      "Backbone params:      27,709,870\n",
      "Head params:           2,288,080\n"
     ]
    }
   ],
   "source": [
    "head = src.comps.heads_glam.RetrievalGLAMHeadPyramidTopDownInstantSimple(\n",
    "    feat_shapes=backbone.feature_shapes,\n",
    "    in_feat_idxs=[0, 1, 2, 3],\n",
    "    emb_size=960,\n",
    "    glam_int_channels_list=[32, 64, 128, 192],\n",
    "    conv1_groups=None\n",
    ")\n",
    "\n",
    "model = torch.nn.Sequential(backbone, head)\n",
    "\n",
    "#\n",
    "\n",
    "input_tensor = torch.rand(1, 3, 224, 224)\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(output_tensor, name=\"Output tensor\")\n",
    "print()\n",
    "\n",
    "print(\"Backbone params: {:15,d}\".format(src.utils.module.get_num_params(backbone)))\n",
    "print(\"Head params:     {:15,d}\".format(src.utils.module.get_num_params(head)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1d9cd8eb66510c5ec86eb907d6561b8001175da1689fbe0f45c40d854d32b14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
