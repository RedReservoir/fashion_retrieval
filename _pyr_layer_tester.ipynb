{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import src.utils.tensor\n",
    "\n",
    "torch.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_l1 = torch.rand((96, 56, 56))\n",
    "feat_l2 = torch.rand((192, 28, 28))\n",
    "feat_l3 = torch.rand((384, 14, 14))\n",
    "feat_l4 = torch.rand((768, 7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: feat\n",
      "shape:  torch.Size([384, 14, 14])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  294.07 KiB\n",
      "\n",
      "name: feat_up\n",
      "shape:  torch.Size([384, 7, 7])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  73.57 KiB\n",
      "\n",
      "1327488\n"
     ]
    }
   ],
   "source": [
    "feat = feat_l3\n",
    "\n",
    "#\n",
    "\n",
    "conv_layer = torch.nn.Conv2d(\n",
    "    in_channels=feat.shape[0],\n",
    "    out_channels=feat.shape[0],\n",
    "    kernel_size=3,\n",
    "    stride=2,\n",
    "    padding=1\n",
    ")\n",
    "\n",
    "feat_up = conv_layer(feat)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(feat, \"feat\", nl=True)\n",
    "src.utils.tensor.print_tensor_info(feat_up, \"feat_up\", nl=True)\n",
    "\n",
    "print(sum(p.numel() for p in conv_layer.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: feat\n",
      "shape:  torch.Size([768, 7, 7])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  147.07 KiB\n",
      "\n",
      "name: feat_up\n",
      "shape:  torch.Size([768, 14, 14])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  588.07 KiB\n",
      "\n",
      "5309184\n"
     ]
    }
   ],
   "source": [
    "feat = feat_l4\n",
    "\n",
    "#\n",
    "\n",
    "conv_transpose_layer = torch.nn.ConvTranspose2d(\n",
    "    in_channels=feat.shape[0],\n",
    "    out_channels=feat.shape[0],\n",
    "    kernel_size=3,\n",
    "    padding=1,\n",
    "    stride=2,\n",
    "    output_padding=1\n",
    ")\n",
    "\n",
    "feat_up = conv_transpose_layer(feat)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(feat, \"feat\", nl=True)\n",
    "src.utils.tensor.print_tensor_info(feat_up, \"feat_up\", nl=True)\n",
    "\n",
    "print(sum(p.numel() for p in conv_transpose_layer.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5309184"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(768 * 768 * 3 * 3) + 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: feat\n",
      "shape:  torch.Size([1152, 14, 14])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  882.07 KiB\n",
      "\n",
      "name: feat_up\n",
      "shape:  torch.Size([512, 14, 14])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  392.07 KiB\n",
      "\n",
      "589824\n"
     ]
    }
   ],
   "source": [
    "feat = torch.rand(1152, 14, 14)\n",
    "\n",
    "#\n",
    "\n",
    "conv_transpose_layer = torch.nn.Conv2d(\n",
    "    in_channels=feat.shape[0],\n",
    "    out_channels=512,\n",
    "    kernel_size=1,\n",
    "    bias=False\n",
    ")\n",
    "\n",
    "feat_up = conv_transpose_layer(feat)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(feat, \"feat\", nl=True)\n",
    "src.utils.tensor.print_tensor_info(feat_up, \"feat_up\", nl=True)\n",
    "\n",
    "print(sum(p.numel() for p in conv_transpose_layer.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: feat\n",
      "shape:  torch.Size([768, 7, 7])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  147.07 KiB\n",
      "\n",
      "name: feat_up\n",
      "shape:  torch.Size([768, 56, 56])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  9.19 MiB\n"
     ]
    }
   ],
   "source": [
    "feat = feat_l4\n",
    "\n",
    "#\n",
    "\n",
    "conv_transpose_layer = torch.nn.Sequential(*[\n",
    "    torch.nn.ConvTranspose2d(\n",
    "        in_channels=feat.shape[0],\n",
    "        out_channels=feat.shape[0],\n",
    "        kernel_size=3,\n",
    "        padding=1,\n",
    "        stride=2,\n",
    "        output_padding=1\n",
    "    )\n",
    "    for _ in range(3)\n",
    "])\n",
    "\n",
    "feat_up = conv_transpose_layer(feat)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(feat, \"feat\", nl=True)\n",
    "src.utils.tensor.print_tensor_info(feat_up, \"feat_up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: feat\n",
      "shape:  torch.Size([768, 7, 7])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  147.07 KiB\n",
      "\n",
      "name: feat_up\n",
      "shape:  torch.Size([768, 28, 28])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  2.30 MiB\n"
     ]
    }
   ],
   "source": [
    "feat = feat_l4\n",
    "\n",
    "#\n",
    "\n",
    "conv_transpose_layer = torch.nn.ConvTranspose2d(\n",
    "    in_channels=feat.shape[0],\n",
    "    out_channels=feat.shape[0],\n",
    "    kernel_size=3,\n",
    "    padding=1,\n",
    "    stride=4,\n",
    "    output_padding=3\n",
    ")\n",
    "\n",
    "feat_up = conv_transpose_layer(feat)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(feat, \"feat\", nl=True)\n",
    "src.utils.tensor.print_tensor_info(feat_up, \"feat_up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: feat\n",
      "shape:  torch.Size([768, 7, 7])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  147.07 KiB\n",
      "\n",
      "name: feat_up\n",
      "shape:  torch.Size([768, 13, 13])\n",
      "dtype:  torch.float32\n",
      "device:  cpu\n",
      "mem:  507.07 KiB\n"
     ]
    }
   ],
   "source": [
    "feat = feat_l4\n",
    "\n",
    "#\n",
    "\n",
    "conv_transpose_layer = torch.nn.ConvTranspose2d(\n",
    "    in_channels=feat.shape[0],\n",
    "    out_channels=feat.shape[0],\n",
    "    kernel_size=3,\n",
    "    padding=1,\n",
    "    stride=2,\n",
    "    dilation=1,\n",
    "    output_padding=0\n",
    ")\n",
    "\n",
    "feat_up = conv_transpose_layer(feat)\n",
    "\n",
    "src.utils.tensor.print_tensor_info(feat, \"feat\", nl=True)\n",
    "src.utils.tensor.print_tensor_info(feat_up, \"feat_up\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "649142fb4cdab8a2d2387ea4a1c8e262f08b2b20e4af0e114d36ea602bf8b868"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
