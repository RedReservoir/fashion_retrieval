{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.transforms import Resize, Lambda, Compose\n",
    "\n",
    "import deep_fashion\n",
    "import backbones, heads, models\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12-07-2023--19:06:12'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "device_idxs = [3, 4, 5, 6]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(idx) for idx in device_idxs])\n",
    "\n",
    "first_device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_memory_usage(device_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(\"log.txt\", 'w') as log_file:\n",
    "    print(torch.cuda.memory_summary(), file=log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metadata = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctsrbm_image_transform = torchvision.models.ResNet50_Weights.DEFAULT.transforms()\n",
    "ctsrbm_image_transform.antialias = True\n",
    "\n",
    "ctsrbm_dataset_dir = os.path.join(pathlib.Path.home(), \"data\", \"DeepFashion\", \"Consumer-to-shop Clothes Retrieval Benchmark\")\n",
    "\n",
    "ctsrbm_dataset = deep_fashion.ConsToShopClothRetrBM(ctsrbm_dataset_dir, ctsrbm_image_transform)\n",
    "\n",
    "cutdown_ratio = 0.02\n",
    "\n",
    "ctsrbm_train_dataset = Subset(ctsrbm_dataset, utils.cutdown_list(ctsrbm_dataset.get_split_mask_idxs(\"train\"), cutdown_ratio))\n",
    "ctsrbm_test_dataset = Subset(ctsrbm_dataset, utils.cutdown_list(ctsrbm_dataset.get_split_mask_idxs(\"test\"), cutdown_ratio))\n",
    "ctsrbm_val_dataset = Subset(ctsrbm_dataset, utils.cutdown_list(ctsrbm_dataset.get_split_mask_idxs(\"val\"), cutdown_ratio))\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 16\n",
    "\n",
    "ctsrbm_train_loader = DataLoader(ctsrbm_train_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "ctsrbm_test_loader = DataLoader(ctsrbm_test_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "ctsrbm_val_loader = DataLoader(ctsrbm_val_dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = backbones.ResNet50Backbone()\n",
    "model = models.RetModel(backbone, 1024).to(first_device)\n",
    "model = torch.nn.DataParallel(model, device_ids=list(range(len(device_idxs))))\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer,\n",
    "    gamma=0.95\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_filename, model, optimizer, scheduler, train_losses, val_losses, training_metadata):\n",
    "\n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.module.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"training_metadata\": training_metadata\n",
    "        }\n",
    "\n",
    "    torch.save(checkpoint, checkpoint_filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_filename):\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_filename)\n",
    "\n",
    "    # Loading model\n",
    "\n",
    "    backbone = backbones.ResNet50Backbone()\n",
    "\n",
    "    model = models.RetModel(backbone, 1024).to(first_device)\n",
    "    model = torch.nn.DataParallel(model, device_ids=list(range(len(device_idxs))))\n",
    "    model.module.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    \n",
    "    # Loading optimizer\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=1e-3,\n",
    "    )\n",
    "    \n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    \n",
    "    # Loading scheduler\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "        optimizer,\n",
    "        gamma=0.95\n",
    "    )\n",
    "\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "    \n",
    "    # Loading other parameters\n",
    "\n",
    "    train_losses = checkpoint[\"train_losses\"]\n",
    "    val_losses = checkpoint[\"val_losses\"]\n",
    "    training_metadata = checkpoint[\"training_metadata\"]\n",
    "\n",
    "    return model, optimizer, scheduler, train_losses, val_losses, training_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(with_tqdm=True):\n",
    "\n",
    "    #total_data_points = []\n",
    "    #time_diffs = []\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loader_gen = ctsrbm_train_loader\n",
    "    if with_tqdm: loader_gen = tqdm(loader_gen)\n",
    "\n",
    "    #time_start = time() \n",
    "\n",
    "    for train_batch in loader_gen:\n",
    "\n",
    "        #time_diff = time() - time_start\n",
    "        #time_diffs.append(time_diff)\n",
    "\n",
    "        #data_points = train_batch[0].size(dim=0)\n",
    "        #total_data_points.append(data_points)\n",
    "\n",
    "        #print(\"Batch start\")\n",
    "        #utils.print_memory_usage(device_idxs)\n",
    "\n",
    "        anc_imgs = train_batch[0]\n",
    "        pos_imgs = train_batch[1]\n",
    "        neg_imgs = train_batch[2]\n",
    "\n",
    "        #print(\"Loaded data\")\n",
    "        #utils.print_memory_usage(device_idxs)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "\n",
    "            anc_emb = model(anc_imgs)\n",
    "            pos_emb = model(pos_imgs)\n",
    "            neg_emb = model(neg_imgs)\n",
    "\n",
    "            #print(\"Model evaluated\")\n",
    "            utils.print_memory_usage(device_idxs)\n",
    "        \n",
    "            triplet_loss = torch.nn.TripletMarginLoss()\n",
    "            loss = triplet_loss(anc_emb, pos_emb, neg_emb)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def val_epoch(with_tqdm=True):\n",
    "\n",
    "    #total_data_points = []\n",
    "    #time_diffs = []\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        loader_gen = ctsrbm_val_loader\n",
    "        if with_tqdm: loader_gen = tqdm(loader_gen)\n",
    "\n",
    "        #time_start = time() \n",
    "\n",
    "        for val_batch in loader_gen:\n",
    "\n",
    "            #time_diff = time() - time_start\n",
    "            #time_diffs.append(time_diff)\n",
    "\n",
    "            #data_points = val_batch[0].size(dim=0)\n",
    "            #total_data_points.append(data_points)\n",
    "\n",
    "            #print(\"Batch start\")\n",
    "            #utils.print_memory_usage(device_idxs)\n",
    "\n",
    "            anc_imgs = val_batch[0]\n",
    "            pos_imgs = val_batch[1]\n",
    "            neg_imgs = val_batch[2]\n",
    "\n",
    "            #print(\"Loaded data\")\n",
    "            #utils.print_memory_usage(device_idxs)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "\n",
    "                anc_emb = model(anc_imgs)\n",
    "                pos_emb = model(pos_imgs)\n",
    "                neg_emb = model(neg_imgs)\n",
    "\n",
    "                #print(\"Model evaluated\")\n",
    "                utils.print_memory_usage(device_idxs)\n",
    "\n",
    "                triplet_loss = torch.nn.TripletMarginLoss()\n",
    "                loss = triplet_loss(anc_emb, pos_emb, neg_emb)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "current_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.freeze_backbone()\n",
    "early_stopper = utils.EarlyStopper(patience=5)\n",
    "max_epoch = current_epoch + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while current_epoch < max_epoch:\n",
    "\n",
    "    current_epoch += 1\n",
    "\n",
    "    print(\"Epoch {:d}\".format(current_epoch))\n",
    "\n",
    "    train_loss = train_epoch()\n",
    "    val_loss = val_epoch()\n",
    "\n",
    "    mean_train_loss = train_loss / len(ctsrbm_train_loader)\n",
    "    mean_val_loss = val_loss / len(ctsrbm_val_loader)\n",
    "\n",
    "    train_losses.append(mean_train_loss)\n",
    "    val_losses.append(mean_val_loss)\n",
    "\n",
    "    if early_stopper.early_stop(mean_val_loss):\n",
    "        break\n",
    "\n",
    "training_metadata[\"stage_1_epochs\"] = current_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.plot(train_time_diffs, np.cumsum(train_data_points))\n",
    "plt.title(\"{:d} workers\".format(num_workers))\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Data points\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"{:d}_workers_{:d}_batch_stage1.png\".format(num_workers, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(pathlib.Path.home(), \"data\", \"checkpoints\", \"fashion_retrieval\")\n",
    "checkpoint_filename = \"resnet50_ret_stage1.pth\"\n",
    "checkpoint_full_filename = os.path.join(checkpoint_dir, checkpoint_filename)\n",
    "\n",
    "save_checkpoint(checkpoint_full_filename, model, optimizer, scheduler, train_losses, val_losses, training_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(pathlib.Path.home(), \"data\", \"checkpoints\", \"fashion_retrieval\")\n",
    "checkpoint_filename = \"resnet50_ret_stage1.pth\"\n",
    "checkpoint_full_filename = os.path.join(checkpoint_dir, checkpoint_filename)\n",
    "\n",
    "model, optimizer, scheduler, train_losses, val_losses, training_metadata = load_checkpoint(checkpoint_full_filename)\n",
    "current_epoch = len(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.unfreeze_backbone()\n",
    "early_stopper = utils.EarlyStopper(patience=5)\n",
    "max_epoch = current_epoch + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_memory_usage(device_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while current_epoch < max_epoch:\n",
    "\n",
    "    current_epoch += 1\n",
    "\n",
    "    print(\"Epoch {:d}\".format(current_epoch))\n",
    "\n",
    "    train_loss = train_epoch()\n",
    "    val_loss = val_epoch()\n",
    "\n",
    "    mean_train_loss = train_loss / len(ctsrbm_train_loader)\n",
    "    mean_val_loss = val_loss / len(ctsrbm_val_loader)\n",
    "\n",
    "    train_losses.append(mean_train_loss)\n",
    "    val_losses.append(mean_val_loss)\n",
    "\n",
    "    if early_stopper.early_stop(mean_val_loss):\n",
    "        break\n",
    "\n",
    "training_metadata[\"stage_2_epochs\"] = current_epoch - training_metadata[\"stage_1_epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(pathlib.Path.home(), \"data\", \"checkpoints\", \"fashion_retrieval\")\n",
    "checkpoint_filename = \"resnet50_ret_stage2.pth\"\n",
    "checkpoint_full_filename = os.path.join(checkpoint_dir, checkpoint_filename)\n",
    "\n",
    "save_checkpoint(checkpoint_full_filename, model, optimizer, scheduler, train_losses, val_losses, training_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"train\", marker=\".\")\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"val\", marker=\".\")\n",
    "\n",
    "plt.axvline(6.5, ymin=0.02, ymax=0.98, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.title(\"Loss - ResNet50 - Ret\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "649142fb4cdab8a2d2387ea4a1c8e262f08b2b20e4af0e114d36ea602bf8b868"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
